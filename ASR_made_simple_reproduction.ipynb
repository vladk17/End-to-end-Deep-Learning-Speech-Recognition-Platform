{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "ASR_made_simple_reproduction.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladk17/End-to-end-Deep-Learning-Speech-Recognition-Platform/blob/master/ASR_made_simple_reproduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB7NW1JybfqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "You can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
        "\n",
        "Instructions for setting up Colab are as follows:\n",
        "1. Open a new Python 3 notebook.\n",
        "2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n",
        "3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n",
        "4. Run this cell to set up dependencies.\n",
        "\"\"\"\n",
        "# If you're using Google Colab and not running locally, run this cell.\n",
        "!pip install wget\n",
        "!apt-get install sox\n",
        "!pip install git+https://github.com/NVIDIA/apex.git\n",
        "\n",
        "!pip install unidecode\n",
        "\n",
        "!mkdir configs\n",
        "!wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/master/examples/asr/configs/jasper_an4.\n",
        "!wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/master/tests/data/jasper_smaller.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAAl7OADbuSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nemo-toolkit\n",
        "!pip install nemo-asr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4DCbCJrb4g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install SoundFile #vk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuMuizxzcE9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is where the an4/ directory will be placed.\n",
        "# Change this if you don't want the data to be extracted in the current directory.\n",
        "data_dir = '.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7gWuthvcOuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import subprocess\n",
        "import tarfile\n",
        "import wget\n",
        "\n",
        "# Download the dataset. This will take a few moments...\n",
        "print(\"******\")\n",
        "if not os.path.exists(data_dir + '/an4_sphere.tar.gz'):\n",
        "    an4_url = 'http://www.speech.cs.cmu.edu/databases/an4/an4_sphere.tar.gz'\n",
        "    an4_path = wget.download(an4_url, data_dir)\n",
        "    print(f\"Dataset downloaded at: {an4_path}\")\n",
        "else:\n",
        "    print(\"Tarfile already exists.\")\n",
        "    an4_path = data_dir + '/an4_sphere.tar.gz'\n",
        "\n",
        "# Untar and convert .sph to .wav (using sox)\n",
        "tar = tarfile.open(an4_path)\n",
        "tar.extractall(path=data_dir)\n",
        "\n",
        "print(\"Converting .sph to .wav...\")\n",
        "sph_list = glob.glob(data_dir + '/an4/**/*.sph', recursive=True)\n",
        "for sph_path in sph_list:\n",
        "    wav_path = sph_path[:-4] + '.wav'\n",
        "    cmd = [\"sox\", sph_path, wav_path]\n",
        "    subprocess.run(cmd)\n",
        "print(\"Finished conversion.\\n******\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YySPYzzycerD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#example_file_name = train_flac_files_list[0]\n",
        "example_file_name = data_dir + '/an4/wav/an4_clstk/mgah/cen2-mgah-b.wav'\n",
        "#audio, sample_rate = librosa.load(example_file_name)\n",
        "audio, sample_rate = sf.read(example_file_name)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (15,7)\n",
        "plt.title(f'Waveform of Audio Example: {example_file_name}')\n",
        "plt.ylabel('Amplitude')\n",
        "\n",
        "_ = librosa.display.waveplot(audio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PNtCOEvcogN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get spectrogram using Librosa's Short-Time Fourier Transform (stft)\n",
        "spec = np.abs(librosa.stft(audio))\n",
        "spec_db = librosa.amplitude_to_db(spec, ref=np.max)  # Decibels\n",
        "\n",
        "# Use log scale to view frequencies\n",
        "librosa.display.specshow(spec_db, y_axis='log', x_axis='time')\n",
        "plt.colorbar()\n",
        "plt.title('Audio Spectrogram');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np6yxoPccs8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the mel spectrogram of our sample\n",
        "mel_spec = librosa.feature.melspectrogram(audio, sr=sample_rate)\n",
        "mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "librosa.display.specshow(\n",
        "    mel_spec_db, x_axis='time', y_axis='mel')\n",
        "plt.colorbar()\n",
        "plt.title('Mel Spectrogram');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoOE4b9Jcxld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/NVIDIA/NeMo.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vS8-U37c2ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install NeMo/."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhyp8gnNc8bA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install frozendict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJfdD29edFtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the ASR collection from collections/nemo_asr\n",
        "!apt-get install libsndfile1\n",
        "# !pip install NeMo/nemo/collections/asr/.\n",
        "\n",
        "# Install the NLP collection from collections/nemo_nlp\n",
        "# !pip install NeMo/nemo/collections/nlp/.\n",
        "\n",
        "# Install the TTS collection from collections/nemo_tts\n",
        "# !pip install NeMo/nemo/collections/tts/."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7okLs3ETdLWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NeMo's \"core\" package\n",
        "import nemo\n",
        "# NeMo's ASR collection\n",
        "import nemo.collections.asr as nemo_asr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2LNwv09UQQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ooFbDRkbVbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import nemo\n",
        "#import nemo_asr #nemo asr collection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpnLed_5bdTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Building Manifest Files --- #\n",
        "import json\n",
        "\n",
        "# Function to build a manifest\n",
        "def build_manifest(transcripts_path, manifest_path, wav_path):\n",
        "    with open(transcripts_path, 'r') as fin:\n",
        "        with open(manifest_path, 'w') as fout:\n",
        "            for line in fin:\n",
        "                # Lines look like this:\n",
        "                # <s> transcript </s> (fileID)\n",
        "                transcript = line[: line.find('(')-1].lower()\n",
        "                transcript = transcript.replace('<s>', '').replace('</s>', '')\n",
        "                transcript = transcript.strip()\n",
        "\n",
        "                file_id = line[line.find('(')+1 : -2]  # e.g. \"cen4-fash-b\"\n",
        "                audio_path = os.path.join(\n",
        "                    data_dir, wav_path,\n",
        "                    file_id[file_id.find('-')+1 : file_id.rfind('-')],\n",
        "                    file_id + '.wav')\n",
        "\n",
        "                duration = librosa.core.get_duration(filename=audio_path)\n",
        "\n",
        "                # Write the metadata to the manifest\n",
        "                metadata = {\n",
        "                    \"audio_filepath\": audio_path,\n",
        "                    \"duration\": duration,\n",
        "                    \"text\": transcript\n",
        "                }\n",
        "                json.dump(metadata, fout)\n",
        "                fout.write('\\n')\n",
        "                \n",
        "# Building Manifests\n",
        "print(\"******\")\n",
        "train_transcripts = data_dir + '/an4/etc/an4_train.transcription'\n",
        "train_manifest = data_dir + '/an4/train_manifest.json'\n",
        "build_manifest(train_transcripts, train_manifest, 'an4/wav/an4_clstk')\n",
        "print(\"Training manifest created.\")\n",
        "\n",
        "test_transcripts = data_dir + '/an4/etc/an4_test.transcription'\n",
        "test_manifest = data_dir + '/an4/test_manifest.json'\n",
        "build_manifest(test_transcripts, test_manifest, 'an4/wav/an4test_clstk')\n",
        "print(\"Test manifest created.\")\n",
        "print(\"******\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Y7O2wrbVbp",
        "colab_type": "text"
      },
      "source": [
        "1. __Neural Module__ is a block that computes a set of outputs from a set of inputs\n",
        "2. Neural Modules' inputs and outputs have __NeuralType__\n",
        "3. NEMO application is a __DAG__ of connected NMs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo5UfqT1bVbr",
        "colab_type": "text"
      },
      "source": [
        "### Path to your dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgWzzXRlbVbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_manifest = \"an4_train.json\"\n",
        "#val_manifest = \"an4_val.json\"\n",
        "print(train_manifest)\n",
        "print(test_manifest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BiO0alJbVbv",
        "colab_type": "text"
      },
      "source": [
        "### Model description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrY7F3DKiScc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ruamel.yaml import YAML\n",
        "\n",
        "# Parse config and pass to model building function\n",
        "config_path = './configs/jasper_smaller.yaml'\n",
        "yaml = YAML(typ='safe')\n",
        "with open(config_path) as f:\n",
        "    params = yaml.load(f)\n",
        "    print(\"******\\nLoaded config file.\\n******\")\n",
        "\n",
        "labels = params['labels']  # Vocab of tokens\n",
        "sample_rate = params['sample_rate']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3K7BXo7bVbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##import toml\n",
        "#jasper_model_definition = toml.load('/home/okuchaiev/repos/gitlab-master/nemo/test/data/jasper_smaller.yaml') #jasper_smaller.yaml\n",
        "#labels = jasper_model_definition['labels']['labels']\n",
        "jasper_model_definition = params\n",
        "#labels = jasper_model_definition['labels']['labels']\n",
        "labels = jasper_model_definition['labels']\n",
        "jasper_model_definition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jvH9nbLbVby",
        "colab_type": "text"
      },
      "source": [
        "### Instatiate necessary Neural Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSBUazJ3q-9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jasper_model_definition['AudioToTextDataLayer']['train']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8sT4v8pklXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# neural_factory = nemo.core.NeuralModuleFactory(\n",
        "#     log_dir=data_dir+f'/an4_tutorial/')    \n",
        "# #    log_dir=data_dir+'/an4_tutorial/')\n",
        "# #    log_dir=data_dir+'/ls_tutorial/')\n",
        "\n",
        "# logger = neural_factory.logger\n",
        "# logger1 = nemo.logging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmefSxeL4asS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neural_factory=nemo.core.NeuralModuleFactory(backend=nemo.core.Backend.PyTorch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKZPOZBPlRFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dir(logger1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QziX5yxlw0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jasper_model_definition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87UpvG3Pl2Q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jasper_model_definition['sample_rate']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86tpsCMnbVb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_layer = nemo_asr.AudioToTextDataLayer(#featurizer_config=jasper_model_definition['input'],\n",
        "                                          manifest_filepath=train_manifest,\n",
        "                                          #labels=labels#, batch_size=6\n",
        "                                          sample_rate=jasper_model_definition['sample_rate'],\n",
        "                                          labels=labels,\n",
        "                                          batch_size=32,                                           \n",
        "                                          shuffle=True#,\n",
        "                                          #**jasper_model_definition['AudioToTextDataLayer']['train']\n",
        "                                           )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdiGt3mEbVb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_preprocessor = nemo_asr.AudioPreprocessing(**jasper_model_definition['input']) #converts wav to mel spectrogramm \n",
        "data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor(**jasper_model_definition['AudioToMelSpectrogramPreprocessor']) #converts wav to mel spectrogramm "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O4LTUuapE1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dir(nemo_asr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfP0hJKHpOxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#help(nemo_asr.SpectrogramAugmentation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFd6w0WlbVb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#spec_augment = nemo_asr.SpectrogramAugmentation(**jasper_model_definition)\n",
        "spec_augment = nemo_asr.SpectrogramAugmentation(rect_masks=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHkxrkZtbVb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jasper_encoder = nemo_asr.JasperEncoder(feat_in=64,**jasper_model_definition['JasperEncoder'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g3XycIubVb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jasper_decoder = nemo_asr.JasperDecoderForCTC(feat_in=1024, num_classes=len(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-vMHLvtbVcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ctc_loss=nemo_asr.CTCLossNN(num_classes=len(labels))\n",
        "ctc_loss = nemo_asr.CTCLossNM(num_classes=len(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNmpT2ENbVcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "greedy_decoder=nemo_asr.GreedyCTCDecoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xweiAz8EbVcG",
        "colab_type": "text"
      },
      "source": [
        "### Describe How Neural Modules are conntected together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lxaVE26bVcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "audio_signal, audio_signal_len, transcript, transcript_len = data_layer()\n",
        "processed_signal, processed_signal_len=data_preprocessor(input_signal=audio_signal,\n",
        "                                                        length=audio_signal_len)\n",
        "aug_signal = spec_augment(input_spec=processed_signal)\n",
        "encoded, encoded_len = jasper_encoder(audio_signal=aug_signal, length=processed_signal_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxr8i45vbVcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1) CTC model\n",
        "log_probs = jasper_decoder(encoder_output=encoded)\n",
        "predictions=greedy_decoder(log_probs=log_probs)\n",
        "loss=ctc_loss(log_probs=log_probs, targets=transcript,\n",
        "             input_length=encoded_len, target_length=transcript_len)\n",
        "tensors_to_evaluate = [predictions, transcript, transcript_len]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDfTxjR6bVcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #2) Instantiate additional Neural Modules\n",
        "# connector=nemo_asr.JasperRNNCnnector(in_channels=1024, out_channels=jasper_model_definition['rnn_decoder']['hidden_size'])\n",
        "# #RNN decoder with attention\n",
        "# rnn_decoder=nemo.backends.pytorch.common.DecoderRNN(voc_size=len(labels), bos_id=1, **jasper_model_definition['rnn_decoder'])\n",
        "# seq_loss=nemo.backends.pytorch.common.SequentialLoss(pad_id=0, smoothing_coef=0.0)\n",
        "\n",
        "# #define second part of DAG\n",
        "# encoded2=connector(tensor=encoded)\n",
        "# log_probs, _=rnn_decoder(targets=transcript,\n",
        "#                         encoder_outputs=encoded2)\n",
        "# loss=seq_loss(log_probs=log_probs, targets=transcript)\n",
        "\n",
        "# #some bookkeeping\n",
        "# labels=['pad', 'bos', 'eos']+labels\n",
        "# tensor_to_evaluate=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6MSNCSKbVcO",
        "colab_type": "text"
      },
      "source": [
        "### Run training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApMinWjxbVcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from nemo_asr.helpers import monitor_asr_train_process\n",
        "from nemo.collections.asr.helpers import monitor_asr_train_progress, \\\n",
        "    process_evaluation_batch, process_evaluation_epoch\n",
        "from functools import partial\n",
        "# train_callback = nemo.core.SimpleLossLoggerCallback(\n",
        "#     tensor_list2string=lambda x: str(x[0].item()),\n",
        "#     tensor_list2string_evl=lambda x: monitor_asr_train_progress(x, labels=labels))\n",
        "train_callback = nemo.core.SimpleLossLoggerCallback(\n",
        "    # Notice that we pass in loss, predictions, and the transcript info.\n",
        "    # Of course we would like to see our training loss, but we need the\n",
        "    # other arguments to calculate the WER.\n",
        "    tensors=[loss, jasper_model_definition, transcript, transcript_len],\n",
        "    # The print_func defines what gets printed.\n",
        "    print_func=partial(\n",
        "        monitor_asr_train_progress,\n",
        "        labels=labels,\n",
        "        # logger=logger\n",
        "        )\n",
        "    )\n",
        "\n",
        "eval_callback = nemo.core.EvaluatorCallback(\n",
        "    eval_tensors=[loss, predictions, transcript, transcript_len],\n",
        "    user_iter_callback=partial(\n",
        "        process_evaluation_batch, labels=labels),\n",
        "    user_epochs_done_callback=partial(\n",
        "        process_evaluation_epoch, \n",
        "        # logger=logger\n",
        "        ),\n",
        "    eval_step=500  # How often we evaluate the model on the test set\n",
        "    )\n",
        "\n",
        "checkpoint_saver_callback = nemo.core.CheckpointCallback(\n",
        "    folder=data_dir+'/an4_checkpoints',\n",
        "    step_freq=1000  # How often checkpoints are saved\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESl2vBDmbVcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#instantiate Neural Factory with supported backend\n",
        "#neural_factory=nemo.core.NeuralModelFactory(backend=nemo.core.Backend.PyTorch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmGZtq0r_SjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(neural_factory.get_trainer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOurhnKLbVcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer = neural_factory.get_trainer(\n",
        "#      params={'optimpizer_kind':'novograd',\n",
        "#             'optimization_params': {'num_epochs':15, 'lr':2e-2,\n",
        "#                                    'weight_decay':1e-4}})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KsJZSqxTbVcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer.train(tensors_to_optimize=[loss],\n",
        "#                callback=[train_callback],\n",
        "#                tensors_to_evaluate=tensors_to_evaluate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYaoArqj9tnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(neural_factory.train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOHhCcGk8DBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# neural_factory.train(\n",
        "#     tensors_to_optimize=[loss],\n",
        "#     callbacks=[train_callback, eval_callback, checkpoint_saver_callback],\n",
        "#     optimizer='novograd',\n",
        "#     optimization_params={\n",
        "#         \"num_epochs\": 100, \"lr\": 0.01, \"weight_decay\": 1e-4\n",
        "#     })\n",
        "\n",
        "neural_factory.train(\n",
        "    tensors_to_optimize=[loss],\n",
        "    callbacks=[train_callback],\n",
        "    optimizer='novograd',\n",
        "    optimization_params={\n",
        "            \"num_epochs\": 100,\n",
        "            \"lr\": 0.01,\n",
        "            \"weight_decay\": 1e-4\n",
        "\n",
        "        }\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-qqBvEfbVcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#jasper_encoder.save_to('jasper_encoder.pt')\n",
        "#jsaper_encoder.freeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIEecIerbVcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neural_factory=nemo.core.NeuralModelFactory(\n",
        "    backend=nemo.core.Backend.PyTorch,\n",
        "    local_rank=args.local_rank,\n",
        "    optimization_level=nemo.core.Optimization.mxprO1,\n",
        "    placement=device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}